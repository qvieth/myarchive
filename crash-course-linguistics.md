# crash course linguistics
- *******what is rendering?
## 1. what is linguistics?
- phonetics
- phonology
- morphology
- syntax
- semantics
- pragmatics

## 2. morphology
- think of roots and stems of trees

## 3. syntax 1 - morphosyntax
- 

## 4. syntax 2 - trees
- 2:49 - the tree diagrams let us see the predicate relationship
    - we talked about in the last episode

## 5. semantics


## ...


## 11. psycholinguistics
- neuroplasticity : the ability of the brain to flexibly build and
    - connect parts of the brain in reponse to injury or as part of learning
- **tips of the tongue** : they might remember its meaning, its first letter, and sometimes
    - how many syllables it has, but they can't quite recall the complete word
    - also there's **tips of the finger**

## 12. language acquisition
- both when we young and when get older
- **critical period**

## 13. language change and historical linguistics


## 15. computational linguistics
- once computer has the digital text, we then need it to figure out :
    1. the meaning of the words
    2. the relationship between them
- text generation
- text to speech
- speech synthesis
- we can also distinguish between what needs to be customized for each human language
    - and what can always stay in computer code
    - that saves programmers and computers time
- tools that perform just 1 or 2 of these subtasks can also be useful by themselves
    - **automatic captioners** may just do the speech to text part
    - **screen readers** may just do text to speech
    - and **search** or **translation** may start with text and skip processing speech entirely
    - a similar set of steps could work for signed languages too :
        - sign-to-text
        - parsing signs
        - processing results
        - **redering** sign output
- supervised learning - unsupervised learning - semisupervised learning =>

- but none of this data just magically appears
- it gets created or gathered by humans, and humans have all sorts of **biases**
* computer science researcher Harini Suresh created a **framework to evaluate bias in machine learning**
    - we can use this framework to see how bias affects the language tools we've discussed in this episode
* sources of bias :
    1. historical bias : when a bias in the world gets reflected in the output the computer produces
    2. representation bias : when some groups aren't as well represented as others in the training data
    3. measurement bias : when the features and labels in the training data don't accurately reflect what we're looking for
    4. aggregation bias : when several groups of data with different characteristics are combined and a single system isn't likely to work well for all of them at once
    5. evalution bias : when researcher measure a program's success based on something users won't find useful
    6. deployment bias : when a system was originally created for reasonable purposes but then gets misused after its release

* **style analysis tools** : can be used to determined whether a historic figure wrote an anonymous book
    * but they can also be misused to identify anonymous whistleblowers
- being aware of these sources of bias is the first step in figuring out how to correct for them

## 16. writing system
